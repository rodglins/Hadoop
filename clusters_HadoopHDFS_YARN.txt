Obs.: Anotações de aula.

Big Data:
É um processo de analise e interpretação de um gde volume de dados, armazenados remotamente. Pode integrar qqr dado coletado sobre um assunto ou empresa, como os registros de compra e venda e mesmo os canais de interação nao digital (telemarketing e call center). Onde há um registro feito, a tecnologia o alcança.

ERP: megabytes
CRM: Gigabytes
WEB: Terabytes (web logs, a/b testing, behavioral targeting, dynamic pricing, search marketing, etc.)
BigData: Petabytes (Mobileweb sentiment, SMS/MMS,user click stream, )

Escalabilidade horizontal

Processamento tradicional: escalabilidade vertical (uso de mainframe cada vez mais poderosas)
processaemnto distribuído: escalabilidade horizontal (não precisa de máquinas tão potentes, aumenta o poder computacional de maneira distribuída)

O que é um cluster?
É um grupo de computadores que trabalham juntos. Provê armazenamento, processamento e gerenciamento de recursos.

O que é um nó?
Computador individual no cluster. O no master (driver) gerencia a distribuição de trabalho para os nós workers

O que é um daemon?
É um programa(serviço) rodando em um nó. Cada um tem sua função no cluster.


-----

Hadoop:
-escalável, confiável, processamento distribuído;
-s.o de big data. 
-usa hardware comum. 
-framework para computação distribuída, com filesystem distribuído (HDFS)
-infraestrutura confiável, capaz de lidar com falhas (hardware, software, rede)

Distros:
OpenSource:
Apache Hadoop

Comercial:
Cloudera (+Hortonworks)
MapR
AWS ElasticMapReduce
Microsoft HDInsight

Core Hadoop:
Processing (Spark; MapReduce); Resouce Management (Yarn); Storage(HDFS)

HDFS:
Hadoop Distributed File System
baseado no Google FS;
Escalável e toterante a falhas;
arquivo texto, sequence file, parquet, AVRO, ORC ...
tamanho mínimo de um bloco(default: 128MB)
-Fator de replicação (default:3)

NameNode
Gerencia o namespace.
Se o Namenode para, o cluster fica inacessível

DataNode
Armazena os blocos de arquivos

Secondary NameNode
Oferece tarefas de ponto de verificação e manutenção do Namenode

Dados separados em blocos;
Replicado em 3;
Namenode armazena os metadados

-----------

Treino prático:

Instalar Oracle VM Virtualbox
Baixar arquivo Everis_BigData-v3.ova
Importar Appliance Virtual
Selecionar arquivo>Importar


sudo service hadoop-hdfs-namenode start
sudo service hadoop-hdfs-secondarynamenode start
sudo service hadoop-hdfs-datanode start
sudo service hadoop-mapreduce-historyserver start
sudo service hadoop-yarn-resourcemanager start
sudo service hadoop-yarn-nodemanager start

sh script_apoio/start_all_service.sh
service hadoop-hdfs-namenode status
free -mh

-Copiar arquivo do hdfs para local
$ hdfs dfs -get /tmp/file_teste.txt

-ingestão manual
$ hdfs dfs -put file_teste.txt /user/everis-bigdata/

sudo -u hdfs hdfs dfs -chmod -R 777 /tmp
ll -h
hdfs dfs -ls -h /
ll /
hdfs dfs -cat /tmp/file_teste.txt |head -10
hdfs dfs -rm /tmp/file_teste.txt
hdfs dfs -mkdir /tmp/delete
hdfs  dfs -ls /tmp
hdfs dfs -cp /tmp/file_teste.txt /tmp/delete/
hdfs dfs -touchz /tmp/delete/empty_file
hdfs  dfs -ls /tmp
hdfs -u dfs -rm -R /tmp/delete
sudo hdfs dfs -du -h /user
sudo -u hdfs fsck /tmp/ -files -blocks
hdfs fsck
------

YARN:
Yet Another Resouce Negotiator:
-Gerenciamento de recursos;
-Gerenciamento e monitoramento de jobs;
-recursos dos nós sao alocados somente qdo -requisitados (via container)

Componentes:
Application: um job submetido ao Hadoop;
Application Master: gerencia a execução e o escalonamento das tarefas (1 por aplicação);
Container: unidade de alocação de recursos (ex. c1 = 1GB RAM, 2 CPU)
Resource Manager: gerenciador global de recursos;
Node Manager: gerencia o ciclo de vida e monitora os recursos do Container.

Scheduler(Resource Manager)>NodeManager >DataNode>>NameNode

Client>Resource Manager>Application Master>

sudo service hadoop-hdfs-namenode start
sudo service hadoop-hdfs-secondarynamenode start
sudo service hadoop-hdfs-datanode start
sudo service hadoop-mapreduce-historyserver start
sudo service hadoop-yarn-resourcemanager start
sudo service hadoop-yarn-nodemanager start

sudo sed -i 's|hdfs://|hdfs://bigdata-srv:8020/|g' /etc/hadoop/conf/yarn-site.xml

sudo -u hdfs yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /tmp/file_teste.txt /tmp/wc_output

sh script_apoio/stop_all_service.sh
sh script_apoio/start_all_service.sh

ssh ip -l nomedousuario
sudo -u hdfs yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /tmp/file_teste.txt /tmp/wc_output

hdfs -cat /tmp/file_teste.txt
hdfs -ls /tmp/wc_output
hdfs dfs -cat /tmp/wc_output/part-r-00000

Log:
sudo -u hdfs yarn logs -applicationId application_(obterNoBrowser) |more

sudo -u hdfs yarn logs -applicationId application_(obterNoBrowser) > wordcount.log


---

HDFS camada de armazenamento do hadoop;
divide os dados em blocos e os distribui pelo cluster
os workers rodam o daemon DataNode e o master o daemin NameNode;
MapReduce: foi o primeiro framework de computação distruida utilizando com o HDFS;
Levou o processamento aos servidores onde o dado está armazenado

Yarn: gerencia os recursos no cluster
trabalha com hdfs para executar as tarefas quando o dado é armazenado
os workers rodam o daemon NodeManager e o mster o daemon ResourceManger
É possivel monitorar os jobs através da porta 8088.


